---
title: "单机多卡"
date: 2024-03-24T21:51:40+08:00
draft: false
weight: 30
---


# 单机多卡

1. 检测GPU数量

- torch.cuda.device_count()
- os.environ["CUDA_VISIBLE_DEVICES"]="0,1"

2. 数据拷贝（多卡）torch.nn.DataParallel (DEPRECATED)

- nn.DataParallel(module.cuda(), device_ids=[0, 1])

> model.module.state_dict()
> model.load_state_dict()

3. 数据拷贝（推荐）torch.nn.parallel.DistributedDataParallel

- 多进程执行多卡训练，效率比较高
```python
torch.distributed.init_process_group("nccl", world_size=n_gpus, rand=args.local_rank)
# 该语句作用相当于CUDA_VISIBLE_DEVICES环境变量
torch.cuda.set_devices(args.local_rank) 

model = DistributedDataParallel(module.cuda(args.local_rank), device_ids=[args.local_rank])
train_smapler = DistributedSampler(train_dataset)
# 源码位于 torch/utils/data/distributed.py


```